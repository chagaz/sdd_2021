{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PC 3 : Apprentissage supervisé et prétraitement - 14 juin 2021 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans ce notebook, nous allons explorer quelques méthodes de prétraitement des données et leur impact sur une régression linéaire. \n",
    "\n",
    "Ce notebook vous permettra ainsi de découvrir des fonctionalités de `scikit-learn` permettant :\n",
    "* d'entrainer et évaluer un algorithme d'apprentissage supervisé\n",
    "* d'encoder des variables qualitatives ;\n",
    "* de ramener des variables à une fourchette de valeurs ;\n",
    "* de transformer des variables pour rapprocher leur distribution de celle d'une gaussienne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# charger numpy as np, matplotlib as plt\n",
    "%pylab inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('font', **{'size': 12}) # règle la taille de police globalement pour les plots (en pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Données\n",
    "Dans ce notebook nous allons travailler avec les données contenues dans le fichier `data/auto-mpg.tsv`. Ces données, obtenues sur https://archive.ics.uci.edu/ml/datasets/Auto+MPG, décrivent des voitures par les variables suivantes :\n",
    "\n",
    "    1. mpg:           consommation (en miles par gallon), continue\n",
    "    2. cylinders:     nombre de cylindres, discrète\n",
    "    3. displacement:  cylindrée, continue\n",
    "    4. horsepower:    chevaux-vapeur, continue\n",
    "    5. weight:        poids, continue\n",
    "    6. acceleration:  accélération, continue\n",
    "    7. model year:    année, discrète\n",
    "    8. origin:        région d'origine, discrète (1=Amérique du Nord ; 2=Europe ; 3=Asie)\n",
    "    9. car name:      nom, chaîne de caractères."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notre but va être de prédire la consommation d'un véhicule à partir des autres variables (à l'exclusion du nom de la voiture, qui est un identifiant unique)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les données\n",
    "df = pd.read_csv(\"data/auto-mpg.tsv\", delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création des matrices X et y de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(df.drop(columns=['mpg', 'car name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(df['mpg'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Séparation en un jeu d'entraînement et un jeu de test\n",
    "\n",
    "Notre but étant de construire un modèle prédictif, nous allons pour l'évaluer mettre de côté une partie des données (20%), le jeu de test, que nous n'utiliserons pas pour l'entraînement. Rappelez-vous que la minimisation du risque empirique ne garantit pas la minimisation du risque : la performance d'un modèle sur les données sur lesquelles il est entraîné peut être excellente, sans que celui-ci fasse de bonnes prédictions sur d'autres individus. Vous pouvez comparer ça à apprendre par cœur le jeu d'entraînement. Nous parlerons plus en détail de sélection et évaluation de modèle au chapitre 8. \n",
    "\n",
    "L'utilisation de l'argument `random_state` garantit que la répartition des individus entre les deux jeux soit toujours la même au sein de ce notebook si vous relancez la commande. Attention, vous n'aurez a priori pas la même que quelqu'un d'autre exécutant le même notebook sur une autre machine, ce qui peut expliquer de fluctuations entre vos résultats et ceux d'une autre personne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, \n",
    "                                                                    test_size=0.20, \n",
    "                                                                    random_state=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Combien d'observations et de variables contiennent, respectivement, le jeu d'échantillon et le jeu de test ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Visualisation des données\n",
    "\n",
    "Nous allons maintenant visualiser les variables représentant nos véhicules. Pour ce faire, nous allons séparer les variables continues (que nous allons représenter chacune par un histogramme) des variables discrètes (que nous allons représenter chacune par un diagramme en barre).\n",
    "\n",
    "Nous nous concentrons sur le jeu d'entraînement : notre but est d'utiliser le jeu de test pour tester les modèles appris sur le jeu d'entraînement, en prétendant ne pas le connaître au moment de l'entraînement.\n",
    "\n",
    "N'hésitez pas à ajuster les paramètres des méthodes de `matplotlib` pour produire des graphiques plus lisibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_features = ['displacement', 'horsepower', 'weight', 'acceleration']\n",
    "discrete_features = ['cylinders', 'model year', 'origin']\n",
    "\n",
    "features = list(df.drop(columns=['mpg', 'car name']).columns)\n",
    "\n",
    "continuous_features_idx = [features.index(feat_name) for feat_name in continuous_features]\n",
    "discrete_features_idx = [features.index(feat_name) for feat_name in discrete_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Histograms for continuous features\n",
    "for (plot_idx, feat_idx) in enumerate(continuous_features_idx):\n",
    "    # create a subplot in the (plot_idx+1) position of a 2x2 grid\n",
    "    ax = fig.add_subplot(2, 2, (plot_idx+1))\n",
    "    # plot the histogram of feat_idx\n",
    "    h = ax.hist(X_train[:, feat_idx], bins=30, edgecolor='none')\n",
    "    # use the name of the feature as a title for each histogram\n",
    "    ax.set_title(features[feat_idx])\n",
    "# espacement entre les subplots\n",
    "fig.tight_layout(pad=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plots for discrete features\n",
    "fig = plt.figure(figsize=(12, 3))\n",
    "\n",
    "for (plot_idx, feat_idx) in enumerate(discrete_features_idx):\n",
    "    # create a subplot in the (plot_idx+1) position of a 1x3 grid\n",
    "    ax = fig.add_subplot(1, 3, (plot_idx+1))\n",
    "\n",
    "    feature_values = np.unique(X_train[:, feat_idx])\n",
    "    frequencies = [(float(len(np.where(X_train[:, feat_idx]==value)[0]))/X_train.shape[0]) \\\n",
    "                   for value in feature_values]\n",
    "    \n",
    "    b = ax.bar(range(len(feature_values)), frequencies, width=0.5, \n",
    "               tick_label=list([int(n) for n in feature_values]))\n",
    "    \n",
    "    # use the name of the feature as a title for each histogram\n",
    "    ax.set_title(features[feat_idx])\n",
    "fig.tight_layout(pad=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Quelles sont les fourchettes de valeur prises par les différentes variables ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Tracer l'histogramme des étiquettes du jeu d'entrainement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y_train, bins=30, edgecolor='none')\n",
    "plt.title('mpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Un premier modèle\n",
    "\n",
    "Nous allons maintenant construire une _baseline_, c'est-à-dire un premier modèle qui nous servira de point de comparaison. Ici, il s'agit d'utiliser `scikit-learn` pour entraîner une régression linéaire sur les données sans les prétraiter.\n",
    "\n",
    "Les modèles linéaires de `scikit-learn` sont implémentés dans le module [`sklearn.linear_model`](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.linear_model). __N'hésitez pas à vous référer fréquemment à la documentation de scikit-learn, qui est très complète.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entraînement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation d'un objet LinearRegression\n",
    "predictor = linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrainement de cet objet sur les données d'entraînement\n",
    "predictor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prédiction sur les données de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = predictor.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance\n",
    "\n",
    "Il s'agit maintenant d'évaluer ces prédictions. Pour cela, nous allons utiliser les fonctionalités du module [https://scikit-learn.org/stable/modules/classes.html?highlight=metrics#module-sklearn.metrics](`metrics`) de `scikit-learn`.\n",
    "\n",
    "Comme il s'agit d'un problème de régression, nous allons utiliser la __RMSE__ (_Root Mean Squared Error_) comme mesure de la performance du modèle : il s'agit de la racine carrée de la moyenne des carrés des erreurs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Pourquoi prendre la racine carrée et pas simplement la MSE ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"RMSE: %.2f\" % metrics.mean_squared_error(y_test, y_pred, squared=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Que pensez-vous de cette erreur ? Est-elle faible? Grande ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons aussi utiliser une visualisation, et représenter chaque individu du jeu de test par son étiquette prédite vs. sa vraie étiquette."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_test, y_pred)\n",
    "\n",
    "plt.xlabel(\"Consommation réelle (mpg)\")\n",
    "plt.ylabel(\"Consommation prédite (mpg)\")\n",
    "plt.title(\"Régression linéaire\")\n",
    "\n",
    "# Mêmes valeurs sur les deux axes\n",
    "axis_min = np.min([np.min(y_test), np.min(y_pred)])-1\n",
    "axis_max = np.max([np.max(y_test), np.max(y_pred)])+1\n",
    "plt.xlim(axis_min, axis_max)\n",
    "plt.ylim(axis_min, axis_max)\n",
    "  \n",
    "# Diagonale y=x\n",
    "plt.plot([axis_min, axis_max], [axis_min, axis_max], 'k-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coefficients de régression\n",
    "\n",
    "Pour comprendre notre modèle, nous pouvons regarder les coefficients affectés à chaque variable dans le modèle linéaire appris."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot, for each feature, its coefficient in the model (here: absolute value)\n",
    "num_features = X_train.shape[1]\n",
    "feature_names = df.drop(columns=['mpg', 'car name']).columns\n",
    "plt.scatter(range(num_features), np.abs(predictor.coef_))\n",
    "\n",
    "plt.xlabel('Variable')\n",
    "tmp = plt.xticks(range(num_features), feature_names, rotation=90)\n",
    "tmp = plt.ylabel('Coefficient')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Quelle variable a le plus fort coefficient (en valeur absolue) ? Pensez-vous que cela signifie que cette variable joue un rôle très important dans la prédiction ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Encodage des variables qualitatives\n",
    "La variable `origin` est une variable qualitative : l'encodage 1-2-3 est tout à fait arbitraire. Il suppose en particulier, si on réfléchit en termes de distances, que l'Asie est deux fois plus loin de l'Amérique du Nord que de l'Europe, ce qui n'a aucun sens.\n",
    "\n",
    "Un encodage plus raisonnable pour ce genre de cas est ce qu'on appelle l'encodage _one-hot_, ou encore _dummy encoding_ : on représente la variable par autant de variables binaires qu'il y a de valeurs possibles (3 dans le cas de la variable `origin` : la première correspond à Amérique du Nord, la deuxième à Europe, la troisième à Asie), et on met à `1` la seule de ces variables binaires correspondant à la valeur que l'on encode.\n",
    "\n",
    "Ainsi l'unique variable `origin` devient 3 variables binaires:\n",
    "```    \n",
    "   Amérique du Nord --> 1, 0, 0\n",
    "   Europe --> 0, 1, 0\n",
    "   Asie --> 0, 0, 1\n",
    "```  \n",
    "Cette représentation a l'inconvénient d'augmenter le nombre de variables, mais les distances euclidiennes sont maintenant plus raisonnables (elles valent 1 si les valeurs sont différentes et 0 si elles sont identiques)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette fonctionalité existe dans `pandas` comme dans `scikit-learn`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer un nouveau data frame où la colomne 'origin' est remplacée par son encodage 'one-hot'\n",
    "df_dummies = pd.get_dummies(df, columns=['origin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraire de nouveau les données\n",
    "X_dummies = np.array(df_dummies.drop(columns=['mpg', 'car name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dummies_train, X_dummies_test, y_d_train, y_d_test = model_selection.train_test_split(X_dummies, y, \n",
    "                                                                                        test_size=0.20, \n",
    "                                                                                        random_state=27)\n",
    "                                                                                                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous pouvez vérifier ici que l'utilisation de la même graine pour `random_state` génère la même répartition des données que précédemment :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.abs(y_d_train-y_train)) + np.sum(np.abs(y_d_test-y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impact sur le modèle\n",
    "\n",
    "Nous allons maintenant apprendre une régression linéaire sur les données où la variable `origin` a été remplacée par son encodage one-hot. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Créer une instance `predictor_dummy` de la classe `LinearRegression` entraînée sur les données contenant la version _one-hot_ de la variable `origin`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Réponse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Créer un array `y_pred_dummy` qui contient les prédictions de la nouvelle régression linéaire sur les données de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Réponse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Quelle est la RMSE, sur le jeu de test, de ce nouveau modèle ? La comparer à la RMSE précédente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Réponse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparaison aux prédictions de la baseline\n",
    "\n",
    "Les performances sont-elles vraiment différentes ? Nous pouvons comparer les prédictions directement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_test, y_pred, label='Baseline')\n",
    "plt.scatter(y_test, y_pred_dummy, label='Avec one-hot')\n",
    "\n",
    "plt.xlabel(\"Étiquettes réelles\")\n",
    "plt.ylabel(\"Étiquettes prédites\")\n",
    "plt.title(\"Régression linéaire\")\n",
    "\n",
    "# Mêmes valeurs sur les deux axes\n",
    "axis_min = np.min([np.min(y_test), np.min(y_pred), np.min(y_pred_dummy)])-1\n",
    "axis_max = np.max([np.max(y_test), np.max(y_pred), np.max(y_pred_dummy)])+1\n",
    "plt.xlim(axis_min, axis_max)\n",
    "plt.ylim(axis_min, axis_max)\n",
    "  \n",
    "# Diagonale y=x\n",
    "plt.plot([axis_min, axis_max], [axis_min, axis_max], 'k-')\n",
    "\n",
    "plt.legend(loc=(0.02, 0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_pred, y_pred_dummy)\n",
    "\n",
    "plt.xlabel(\"Étiquettes prédites (baseline)\")\n",
    "plt.ylabel(\"Étiquettes prédites (avec one-hot)\")\n",
    "plt.title(\"Régression linéaire\")\n",
    "\n",
    "# Mêmes valeurs sur les deux axes\n",
    "axis_min = np.min([np.min(y_pred), np.min(y_pred_dummy)])-1\n",
    "axis_max = np.max([np.max(y_pred), np.max(y_pred_dummy)])+1\n",
    "plt.xlim(axis_min, axis_max)\n",
    "plt.ylim(axis_min, axis_max)\n",
    "  \n",
    "# Diagonale y=x\n",
    "plt.plot([axis_min, axis_max], [axis_min, axis_max], 'k-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r, pval = st.pearsonr(y_pred, y_pred_dummy)\n",
    "print(\"Corrélation entre les prédictions : %.2f (p=%.2e)\" % (r, pval))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coefficients de régression\n",
    "\n",
    "Comparons maintenant les deux modèles visuellement :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot, for each feature, its coefficient in the model (here: absolute value)\n",
    "num_features = X_train.shape[1]\n",
    "plt.scatter(range(num_features), np.abs(predictor.coef_), label='Original')\n",
    "\n",
    "num_features2 = X_dummies_train.shape[1]\n",
    "plt.scatter(range(num_features2), np.abs(predictor_dummy.coef_), label='Avec one-hot', marker='v')\n",
    "feature_names2 = df_dummies.drop(columns=['mpg', 'car name']).columns\n",
    "\n",
    "plt.xlabel('Variable')\n",
    "tmp = plt.xticks(range(num_features2), feature_names2, rotation=90)\n",
    "tmp = plt.ylabel('Coefficient')\n",
    "\n",
    "plt.legend(loc=(0.02, 0.75))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Ce modèle est-il vraiment différent du précédent ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Ramener les variables à des échelles comparables\n",
    "\n",
    "Le fait que les variables soient sur des échelles différentes rend l'interprétation des coefficients de la régression linéaire délicate. \n",
    "\n",
    "### 5.1 Centrer et réduire les variables\n",
    "\n",
    "Centrer et réduire les variables (comme nous l'avons vu dans la PC2) permet de remédier à ce problème."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformation des variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_scaler = preprocessing.StandardScaler()\n",
    "standard_scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = standard_scaler.transform(X_train)\n",
    "X_test_scaled = standard_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualisation des nouvelles variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 10))\n",
    "\n",
    "# Histograms for continuous features\n",
    "for (plot_idx, feat_idx) in enumerate(continuous_features_idx):\n",
    "    # create subplot\n",
    "    ax = fig.add_subplot(4, 2, (2*plot_idx+1))\n",
    "    # plot the original histogram of feat_idx\n",
    "    h = ax.hist(X_train[:, feat_idx], bins=30, edgecolor='none')\n",
    "    # use the name of the feature as a title for each histogram\n",
    "    ax.set_title(\"%s (original)\" % features[feat_idx])    \n",
    "    \n",
    "    # create subplot\n",
    "    ax = fig.add_subplot(4, 2, (2*plot_idx+2))\n",
    "    # plot the new histogram of feat_idx\n",
    "    h = ax.hist(X_train_scaled[:, feat_idx], bins=30, edgecolor='none', color='orange')\n",
    "    # use the name of the feature as a title for each histogram\n",
    "    ax.set_title(\"%s (centrée-réduite)\" % features[feat_idx])\n",
    "    \n",
    "# espacement entre les subplots\n",
    "fig.tight_layout(pad=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plots for discrete features\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Original features\n",
    "for (plot_idx, feat_idx) in enumerate(discrete_features_idx):\n",
    "    # create a subplot\n",
    "    ax = fig.add_subplot(2, 3, (plot_idx+1))\n",
    "    # create bar plot\n",
    "    feature_values = np.unique(X_train[:, feat_idx])\n",
    "    frequencies = [(float(len(np.where(X_train[:, feat_idx]==value)[0]))/X_train.shape[0]) \\\n",
    "                   for value in feature_values]\n",
    "    tick_labels = feature_values.astype(int)\n",
    "    b = ax.bar(range(len(feature_values)), frequencies, width=0.5, tick_label=tick_labels)    \n",
    "    # use the name of the feature as a title for each histogram\n",
    "    ax.set_title(\"%s (originale)\" % features[feat_idx])\n",
    "\n",
    "# Transformed features\n",
    "for (plot_idx, feat_idx) in enumerate(discrete_features_idx):\n",
    "    # create a subplot\n",
    "    ax = fig.add_subplot(2, 3, (3+plot_idx+1))\n",
    "    # create bar plot\n",
    "    feature_values = np.unique(X_train_scaled[:, feat_idx])\n",
    "    frequencies = [(float(len(np.where(X_train_scaled[:, feat_idx]==value)[0]))/X_train_scaled.shape[0]) \\\n",
    "                   for value in feature_values]\n",
    "    tick_labels = [\"%.2f\" % v for v in feature_values]\n",
    "    b = ax.bar(range(len(feature_values)), frequencies, width=0.5, \n",
    "               tick_label=tick_labels, color='orange')    \n",
    "    # use the name of the feature as a title for each histogram\n",
    "    ax.set_title(\"%s (centrée-réduite)\" % features[feat_idx])\n",
    "fig.tight_layout(pad=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Impact sur le modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Entrainez un modèle `predictor_scaled` sur les données centrées-réduites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Réponse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Créer un array `y_pred_scaled` qui contient les prédictions de `predictor_scaled` sur le jeu de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Réponse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Quelle est la RMSE, sur le jeu de test, de ce nouveau modèle ? La comparer à la RMSE précédente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Réponse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Comparer les coefficients de régression des deux modèles. Quelles sont les variables les plus pertinentes pour prédire la consommation d'un véhicule ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Réponse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 [Pour aller plus loin] Réduction min-max\n",
    "La réduction min-max est une autre façon de ramener les variables sur une même échelle, en les ramenant entre 0 et 1 par $x_j \\leftarrow (x_j - \\max(x_j))/(\\max(x_j)-\\min(x_j))$.\n",
    "\n",
    "Dans `scikit-learn`, elle est implémentée de manière très simimlaire à `StandardScaler` dans `preprocessing.MinMaxScaler()`. \n",
    "\n",
    "__Question :__ Reproduisez l'analyse de la section 5.1 avec cette nouvelle transformation des données. Les résultats sont-ils différents de la section 5.1 ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. [Pour aller plus loin] Normalisation des variables\n",
    "\n",
    "Vous l'aurez remarqué en regardant les histogrammes : nos variables continues ne semblent pas suivre une distribution normale. \n",
    "\n",
    "Dans le cas de la régression linéaire, nous n'avons fait aucune hypothèse sur la normalité des variables : nous avons supposés que les résidus sont normalement distribués. Cependant, transformer les variables pour les rapprocher de gaussiennes peut permettre d'améliorer les modèles, en particulier en contrôlant l'[asymétrie](https://fr.wikipedia.org/wiki/Asym%C3%A9trie_(statistiques)) des valeurs. \n",
    "\n",
    "`scikit-learn` permet d'appliquer deux types de transformations normales des variables : \n",
    "* la transformation Box-Cox, qui ne s'applique qu'à des variables non nulles positives. C'est cette première que nous allons illustrer ici.\n",
    "* la transformation de Yeo-Johnson.\n",
    "Ces deux méthodes sont disponibles dans la classe [`sklearn.preprocessing.PowerTransformer`](https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing-transformer) et vous pouvez en lire plus à leur sujet dans [la doc](https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing-transformer).\n",
    "\n",
    "__Remarque pour aller plus loin:__ Un histogramme n'est pas un très bon moyen de vérifier qu'une distribution empirique correspond à une distribution théorique. On leur préfère plutôt un [graphe quantile-quantile (QQ-plot)](https://fr.wikipedia.org/wiki/Diagramme_quantile-quantile) ou... un test statistique (pour la normalité, on utilise par exemple le [test de Shapiro-Wilk](https://fr.wikipedia.org/wiki/Test_de_Shapiro-Wilk) ou le [test de Kolmogorov-Smirnov](https://fr.wikipedia.org/wiki/Test_de_Kolmogorov-Smirnov). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation Box-Cox des variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxcox_scaler = preprocessing.PowerTransformer(method='box-cox')\n",
    "boxcox_scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_boxcox = boxcox_scaler.transform(X_train)\n",
    "X_test_boxcox = boxcox_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation des variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Histograms for continuous features\n",
    "for (plot_idx, feat_idx) in enumerate(continuous_features_idx): \n",
    "    # create subplot\n",
    "    ax = fig.add_subplot(2, 2, (plot_idx+1))\n",
    "    # plot the new histogram of feat_idx\n",
    "    h = ax.hist(X_train_scaled[:, feat_idx], bins=30, edgecolor='none', color='orange', alpha=0.75, \n",
    "               label='centrée-réduite')\n",
    "    \n",
    "    # plot the new histogram of feat_idx\n",
    "    h = ax.hist(X_train_boxcox[:, feat_idx], bins=30, edgecolor='none', color='purple', alpha=0.75,\n",
    "               label='Box-Cox')\n",
    "    \n",
    "    # use the name of the feature as a title for each histogram\n",
    "    ax.set_title(\"%s\" % features[feat_idx])\n",
    "    \n",
    "    ax.legend(loc=(0.7, 0.7))\n",
    "    \n",
    "# espacement entre les subplots\n",
    "fig.tight_layout(pad=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impact sur le modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question :__ Quel est l'impact de cette transformation sur le modèle ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Pour aller encore plus loin\n",
    "\n",
    "Le pré-traitement des données est une partie importante du travail de _data scientist_. Voici quelques ressources et remarques pour aller plus loin :\n",
    "* La transformation en vecteurs de données non-structurées (telles que texte ou images) est possible à travers des techniques telles que :\n",
    "  * pour le texte : les approches bag-of-word ou tf-idf (voir [la doc scikit-learn](https://scikit-learn.org/stable/modules/feature_extraction.html#feature-extraction) ou [le cours OpenClassrooms Analysez vos données textuelles](https://openclassrooms.com/fr/courses/4470541-analysez-vos-donnees-textuelles);\n",
    "  * pour les images : les approches telles que SIFT (voir [le cours OpenClassrooms Classez et segmentez des données visuelles](https://openclassrooms.com/fr/courses/4470531-classez-et-segmentez-des-donnees-visuelles).\n",
    "  \n",
    "* Les méthodes à noyaux et l'apprentissage profond, que nous aborderons brièvement à la fin de ce cours, permettent d'aborder autrement la représentation de données non-structurées.\n",
    "\n",
    "* https://github.com/mirekphd/awesome-feature-engineering\n",
    "* https://machinelearningmastery.com/discover-feature-engineering-how-to-engineer-features-and-how-to-get-good-at-it/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
